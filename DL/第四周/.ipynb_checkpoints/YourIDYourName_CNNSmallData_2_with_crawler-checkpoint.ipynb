{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"data_raw\"\n",
    "\n",
    "# 训练 / 验证 / 测试集的目标根目录\n",
    "BASE_DIR = \"data_small\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR   = os.path.join(BASE_DIR, \"validation\")\n",
    "TEST_DIR  = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "RAW_CLASSES_KEYWORDS = [\"husky dog\", \"ragdoll cat\", \"golden retriever\"]\n",
    "\n",
    "# 从关键词生成合法的文件夹名\n",
    "def keyword_to_classname(keyword: str) -> str:\n",
    "    return \"\".join(ch if ch.isalnum() else \"_\" for ch in keyword.strip()).strip(\"_\").lower()\n",
    "\n",
    "CLASSES = [keyword_to_classname(kw) for kw in RAW_CLASSES_KEYWORDS]\n",
    "\n",
    "# 每类图片预计下载数量\n",
    "N_PER_CLASS = 80\n",
    "\n",
    "# 数据集划分比例\n",
    "TRAIN_RATIO = 0.6\n",
    "VAL_RATIO   = 0.2\n",
    "TEST_RATIO  = 0.2\n",
    "\n",
    "# 图像大小\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH  = 150\n",
    "IMG_CHANNELS = 3\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "# 训练相关超参数\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_BASELINE  = 30   # 基准 CNN\n",
    "EPOCHS_AUG       = 60   # 数据增强 CNN\n",
    "EPOCHS_TRANSFER  = 30   # 迁移学习（VGG16 / ResNet 基础阶段）\n",
    "EPOCHS_FINETUNE  = 60   # 微调阶段\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(\"关键词：\", RAW_CLASSES_KEYWORDS)\n",
    "print(\"类别名：\", CLASSES)\n",
    "print(\"目标类别数:\", NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_images_in_dir(directory, classes):\n",
    "    \"\"\"统计某个目录下每一类图片数量，并返回总数。\"\"\"\n",
    "    exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "    total = 0\n",
    "    for cls in classes:\n",
    "        cls_dir = os.path.join(directory, cls)\n",
    "        if not os.path.exists(cls_dir):\n",
    "            print(f\"[{os.path.basename(directory)}] 类别 {cls}: 目录不存在\")\n",
    "            continue\n",
    "        n = len([f for f in os.listdir(cls_dir) if f.lower().endswith(exts)])\n",
    "        print(f\"[{os.path.basename(directory)}] 类别 {cls}: {n} 张\")\n",
    "        total += n\n",
    "    print(f\"总计：{total} 张\\n\")\n",
    "    return total\n",
    "\n",
    "\n",
    "def plot_training_curves(history, title_prefix=\"\"):\n",
    "    \"\"\"画出训练 / 验证集的准确率和损失曲线。\"\"\"\n",
    "    acc = history.history.get(\"acc\") or history.history.get(\"accuracy\")\n",
    "    val_acc = history.history.get(\"val_acc\") or history.history.get(\"val_accuracy\")\n",
    "    loss = history.history.get(\"loss\")\n",
    "    val_loss = history.history.get(\"val_loss\")\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "    plt.title(f\"{title_prefix} Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(f\"{title_prefix} Training and validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def build_simple_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "        metrics=[\"acc\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、数据准备\n",
    "\n",
    "### 1. 自动爬取图像数据集（作业 2-(1)）\n",
    "\n",
    "> 要求：自选一个图像分类主题，爬取 **≥ 3 类** 图片，每类 **≥ 50 张**。  \n",
    "\n",
    "下面给出一个**可直接运行的爬虫实现**，基于第三方库 `simple_image_download`：\n",
    "\n",
    "- 使用 `RAW_CLASSES_KEYWORDS` 里的关键词去搜索图片  \n",
    "- 例如：`[\"husky dog\", \"ragdoll cat\", \"golden retriever\"]`  \n",
    "- 下载的图片会自动整理到：`data_raw/<类别名>/*.jpg`  \n",
    "\n",
    "> 你需要做的只有两步：\n",
    "> 1. 修改上一格代码中的 `RAW_CLASSES_KEYWORDS` 为你想要的类别关键词  \n",
    "> 2. 运行下面这格代码（第一次运行前先 `pip install simple_image_download`）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_image_download import simple_image_download as simp\n",
    "\n",
    "def download_images_for_classes():\n",
    "    os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "\n",
    "    for keyword, cls in zip(RAW_CLASSES_KEYWORDS, CLASSES):\n",
    "        print(f\"=== 正在下载类别：{cls}（搜索关键词：{keyword}） ===\")\n",
    "        response = simp.simple_image_download()\n",
    "        # 下载到 ./simple_images/<keyword>/ 目录\n",
    "        response.download(keyword, N_PER_CLASS, extensions=['.jpg', '.png'])\n",
    "\n",
    "        src_dir = os.path.join(\"simple_images\", keyword)\n",
    "        dst_dir = os.path.join(RAW_DATA_DIR, cls)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "        if not os.path.exists(src_dir):\n",
    "            print(f\"  [警告] 未找到目录 {src_dir}，可能下载失败或关键词不匹配\")\n",
    "            continue\n",
    "\n",
    "        exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "        n = 0\n",
    "        for fname in os.listdir(src_dir):\n",
    "            if not fname.lower().endswith(exts):\n",
    "                continue\n",
    "            src_path = os.path.join(src_dir, fname)\n",
    "            # 为避免重名，加上 cls 前缀\n",
    "            new_name = f\"{cls}_{fname}\"\n",
    "            dst_path = os.path.join(dst_dir, new_name)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "            n += 1\n",
    "\n",
    "        print(f\"  已复制 {n} 张图片到 {dst_dir}\")\n",
    "\n",
    "    print(\"\\n全部类别下载与整理完成。\")\n",
    "    print(\"=== RAW_DATA_DIR 中图片数量统计 ===\")\n",
    "    count_images_in_dir(RAW_DATA_DIR, CLASSES)\n",
    "\n",
    "\n",
    "# 调用一次进行下载\n",
    "download_images_for_classes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 划分训练 / 验证 / 测试集\n",
    "\n",
    "将 `data_raw/<类别>` 中的图片划分为：  \n",
    "\n",
    "- `data_small/train/<类别>`  \n",
    "- `data_small/validation/<类别>`  \n",
    "- `data_small/test/<类别>`  \n",
    "\n",
    "默认按照 `TRAIN_RATIO : VAL_RATIO : TEST_RATIO = 0.6 : 0.2 : 0.2` 划分。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 4. 划分数据集并拷贝图片\n",
    "# ======================\n",
    "\n",
    "def prepare_dataset():\n",
    "    os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(VAL_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 为 train/val/test 创建子目录\n",
    "    for split_dir in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "        for cls in CLASSES:\n",
    "            cls_dir = os.path.join(split_dir, cls)\n",
    "            os.makedirs(cls_dir, exist_ok=True)\n",
    "\n",
    "    exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "\n",
    "    for cls in CLASSES:\n",
    "        src_dir = os.path.join(RAW_DATA_DIR, cls)\n",
    "        if not os.path.exists(src_dir):\n",
    "            print(f\"警告：{src_dir} 不存在，请确认爬虫是否成功下载该类图片。\")\n",
    "            continue\n",
    "\n",
    "        # 如果目标 train 里已经有图片，默认认为已经划分过，避免重复复制\n",
    "        dst_train_cls_dir = os.path.join(TRAIN_DIR, cls)\n",
    "        if len(os.listdir(dst_train_cls_dir)) > 0:\n",
    "            print(f\"{cls} 已经划分过数据集，如需重新划分请先手动清空 data_small 目录。\")\n",
    "            continue\n",
    "\n",
    "        images = [f for f in os.listdir(src_dir) if f.lower().endswith(exts)]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        n_total = len(images)\n",
    "        n_train = int(n_total * TRAIN_RATIO)\n",
    "        n_val   = int(n_total * VAL_RATIO)\n",
    "        n_test  = n_total - n_train - n_val\n",
    "\n",
    "        print(f\"{cls}: 总数 {n_total}, 训练 {n_train}, 验证 {n_val}, 测试 {n_test}\")\n",
    "\n",
    "        train_imgs = images[:n_train]\n",
    "        val_imgs   = images[n_train:n_train+n_val]\n",
    "        test_imgs  = images[n_train+n_val:]\n",
    "\n",
    "        for fname in train_imgs:\n",
    "            shutil.copy(os.path.join(src_dir, fname),\n",
    "                        os.path.join(TRAIN_DIR, cls, fname))\n",
    "        for fname in val_imgs:\n",
    "            shutil.copy(os.path.join(src_dir, fname),\n",
    "                        os.path.join(VAL_DIR, cls, fname))\n",
    "        for fname in test_imgs:\n",
    "            shutil.copy(os.path.join(src_dir, fname),\n",
    "                        os.path.join(TEST_DIR, cls, fname))\n",
    "\n",
    "    print(\"数据划分完成。\")\n",
    "\n",
    "\n",
    "# 调用一次进行数据划分（如已划分好，可跳过）\n",
    "prepare_dataset()\n",
    "\n",
    "print(\"=== 统计划分后图片数量 ===\")\n",
    "n_train = count_images_in_dir(TRAIN_DIR, CLASSES)\n",
    "n_val   = count_images_in_dir(VAL_DIR, CLASSES)\n",
    "n_test  = count_images_in_dir(TEST_DIR, CLASSES)\n",
    "\n",
    "steps_per_epoch = math.ceil(n_train / BATCH_SIZE)\n",
    "val_steps       = math.ceil(n_val / BATCH_SIZE)\n",
    "test_steps      = math.ceil(n_test / BATCH_SIZE)\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"val_steps:\", val_steps)\n",
    "print(\"test_steps:\", test_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、基准 CNN 模型（作业 2-(2)）\n",
    "\n",
    "本节在你爬取的数据集上，建立一个**不使用数据增强**的 CNN 基准模型，用于后续对比。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 5. 基准 CNN 模型（无数据增强）\n",
    "# ======================\n",
    "\n",
    "train_datagen_base = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen_base   = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen_base  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_base = train_datagen_base.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator_base = val_datagen_base.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_generator_base = test_datagen_base.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model_baseline = build_simple_cnn(INPUT_SHAPE, NUM_CLASSES)\n",
    "model_baseline.summary()\n",
    "\n",
    "history_baseline = model_baseline.fit(\n",
    "    train_generator_base,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS_BASELINE,\n",
    "    validation_data=val_generator_base,\n",
    "    validation_steps=val_steps\n",
    ")\n",
    "\n",
    "plot_training_curves(history_baseline, title_prefix=\"[2] Baseline CNN\")\n",
    "\n",
    "test_loss_baseline, test_acc_baseline = model_baseline.evaluate(\n",
    "    test_generator_base,\n",
    "    steps=test_steps\n",
    ")\n",
    "print(\"Baseline CNN - 测试集准确率: {:.4f}\".format(test_acc_baseline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、加入数据增强的 CNN（作业 2-(3)）\n",
    "\n",
    "在基准 CNN 的基础上，对训练集使用随机旋转、平移、缩放、水平翻转等数据增强，以缓解过拟合。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 6. 使用数据增强的 CNN 模型\n",
    "# ======================\n",
    "\n",
    "train_datagen_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "val_datagen_aug  = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator_aug = val_datagen_aug.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_generator_aug = test_datagen_aug.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model_aug = build_simple_cnn(INPUT_SHAPE, NUM_CLASSES)\n",
    "model_aug.summary()\n",
    "\n",
    "history_aug = model_aug.fit(\n",
    "    train_generator_aug,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS_AUG,\n",
    "    validation_data=val_generator_aug,\n",
    "    validation_steps=val_steps\n",
    ")\n",
    "\n",
    "plot_training_curves(history_aug, title_prefix=\"[3] CNN + Data Augmentation\")\n",
    "\n",
    "test_loss_aug, test_acc_aug = model_aug.evaluate(\n",
    "    test_generator_aug,\n",
    "    steps=test_steps\n",
    ")\n",
    "print(\"CNN + Data Augmentation - 测试集准确率: {:.4f}\".format(test_acc_aug))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、直接使用预训练 VGG16（冻结卷积基）（作业 2-(4)）\n",
    "\n",
    "按 PPT 做法：\n",
    "\n",
    "1. 载入在 ImageNet 上预训练好的 **VGG16 卷积基**（`include_top=False`）。  \n",
    "2. **冻结卷积基参数**，只在其顶部添加新的全连接分类器，对自己的数据集进行训练。  \n",
    "3. 使用 `ImageDataGenerator` + 数据增强进行端到端训练。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 7. VGG16 迁移学习（冻结卷积基）\n",
    "# ======================\n",
    "\n",
    "conv_base_vgg = VGG16(weights=\"imagenet\",\n",
    "                      include_top=False,\n",
    "                      input_shape=INPUT_SHAPE)\n",
    "print(conv_base_vgg.summary())\n",
    "\n",
    "conv_base_vgg.trainable = False\n",
    "\n",
    "model_vgg_frozen = models.Sequential()\n",
    "model_vgg_frozen.add(conv_base_vgg)\n",
    "model_vgg_frozen.add(layers.Flatten())\n",
    "model_vgg_frozen.add(layers.Dense(256, activation=\"relu\"))\n",
    "model_vgg_frozen.add(layers.Dropout(0.5))\n",
    "model_vgg_frozen.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "\n",
    "model_vgg_frozen.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model_vgg_frozen.summary()\n",
    "\n",
    "train_datagen_vgg = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "val_test_datagen_vgg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_vgg = train_datagen_vgg.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator_vgg = val_test_datagen_vgg.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_generator_vgg = val_test_datagen_vgg.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "history_vgg_frozen = model_vgg_frozen.fit(\n",
    "    train_generator_vgg,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS_TRANSFER,\n",
    "    validation_data=val_generator_vgg,\n",
    "    validation_steps=val_steps\n",
    ")\n",
    "\n",
    "plot_training_curves(history_vgg_frozen, title_prefix=\"[4] VGG16 Frozen Conv Base\")\n",
    "\n",
    "test_loss_vgg_frozen, test_acc_vgg_frozen = model_vgg_frozen.evaluate(\n",
    "    test_generator_vgg,\n",
    "    steps=test_steps\n",
    ")\n",
    "print(\"VGG16 Frozen Conv Base - 测试集准确率: {:.4f}\".format(test_acc_vgg_frozen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、VGG16 特征提取 + 全连接分类器（作业 2-(5)）\n",
    "\n",
    "对应 PPT 中 **“卷积基用法 1：先提特征，再训练 Dense 分类器”**。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 8. VGG16 卷积基特征提取\n",
    "# ======================\n",
    "\n",
    "conv_base_fe = VGG16(weights=\"imagenet\",\n",
    "                     include_top=False,\n",
    "                     input_shape=INPUT_SHAPE)\n",
    "print(conv_base_fe.summary())\n",
    "\n",
    "datagen_fe = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def extract_features(directory, sample_count, batch_size=BATCH_SIZE):\n",
    "    \"\"\"使用 VGG16 卷积基提取特征 (samples, 4, 4, 512) 和 one-hot 标签。\"\"\"\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512), dtype=np.float32)\n",
    "    labels = np.zeros(shape=(sample_count, NUM_CLASSES), dtype=np.float32)\n",
    "\n",
    "    generator = datagen_fe.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base_fe.predict(inputs_batch)\n",
    "        start = i * batch_size\n",
    "        end = start + inputs_batch.shape[0]\n",
    "        features[start:end] = features_batch\n",
    "        labels[start:end] = labels_batch\n",
    "        i += 1\n",
    "        if end >= sample_count:\n",
    "            break\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "print(\"开始提取训练集特征...\")\n",
    "train_features, train_labels = extract_features(TRAIN_DIR, n_train, BATCH_SIZE)\n",
    "print(\"开始提取验证集特征...\")\n",
    "val_features, val_labels = extract_features(VAL_DIR, n_val, BATCH_SIZE)\n",
    "print(\"开始提取测试集特征...\")\n",
    "test_features, test_labels = extract_features(TEST_DIR, n_test, BATCH_SIZE)\n",
    "\n",
    "train_features = np.reshape(train_features, (n_train, 4 * 4 * 512))\n",
    "val_features   = np.reshape(val_features,   (n_val,   4 * 4 * 512))\n",
    "test_features  = np.reshape(test_features,  (n_test,  4 * 4 * 512))\n",
    "\n",
    "model_fe = models.Sequential()\n",
    "model_fe.add(layers.Dense(256, activation=\"relu\", input_dim=4 * 4 * 512))\n",
    "model_fe.add(layers.Dropout(0.5))\n",
    "model_fe.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "\n",
    "model_fe.compile(\n",
    "    optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "history_fe = model_fe.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=EPOCHS_TRANSFER,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_features, val_labels)\n",
    ")\n",
    "\n",
    "plot_training_curves(history_fe, title_prefix=\"[5] VGG16 Feature Extraction\")\n",
    "\n",
    "test_loss_fe, test_acc_fe = model_fe.evaluate(test_features, test_labels)\n",
    "print(\"VGG16 Feature Extraction - 测试集准确率: {:.4f}\".format(test_acc_fe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、微调 VGG16 顶部卷积层（作业 2-(6)）\n",
    "\n",
    "在 (4) 的基础上进行**微调（fine-tuning）**：\n",
    "\n",
    "1. 先使用冻结卷积基的模型训练好顶部 Dense 分类器；  \n",
    "2. 再将 VGG16 的**顶部若干卷积层解冻**（例如从 `block5_conv1` 开始）；  \n",
    "3. 用较小的学习率继续训练整个网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 9. 微调 VGG16 顶部卷积块\n",
    "# ======================\n",
    "\n",
    "conv_base_vgg.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base_vgg.layers:\n",
    "    if layer.name == \"block5_conv1\":\n",
    "        set_trainable = True\n",
    "    layer.trainable = set_trainable\n",
    "\n",
    "model_vgg_frozen.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model_vgg_frozen.summary()\n",
    "\n",
    "history_vgg_finetune = model_vgg_frozen.fit(\n",
    "    train_generator_vgg,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS_FINETUNE,\n",
    "    validation_data=val_generator_vgg,\n",
    "    validation_steps=val_steps\n",
    ")\n",
    "\n",
    "plot_training_curves(history_vgg_finetune, title_prefix=\"[6] VGG16 Fine-tune Top Block\"]\n",
    "\n",
    "test_loss_vgg_finetune, test_acc_vgg_finetune = model_vgg_frozen.evaluate(\n",
    "    test_generator_vgg,\n",
    "    steps=test_steps\n",
    ")\n",
    "print(\"VGG16 Fine-tuned - 测试集准确率: {:.4f}\".format(test_acc_vgg_finetune))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七、更换预训练模型 ResNet50（作业 2-(7)）\n",
    "\n",
    "将 VGG16 换成另外一个预训练模型 **ResNet50**，比较性能差异。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 10. 使用 ResNet50 预训练模型\n",
    "# ======================\n",
    "\n",
    "conv_base_resnet = ResNet50(weights=\"imagenet\",\n",
    "                            include_top=False,\n",
    "                            input_shape=INPUT_SHAPE)\n",
    "print(conv_base_resnet.summary())\n",
    "\n",
    "conv_base_resnet.trainable = False\n",
    "\n",
    "model_resnet = models.Sequential()\n",
    "model_resnet.add(conv_base_resnet)\n",
    "model_resnet.add(layers.GlobalAveragePooling2D())\n",
    "model_resnet.add(layers.Dense(256, activation=\"relu\"))\n",
    "model_resnet.add(layers.Dropout(0.5))\n",
    "model_resnet.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "\n",
    "model_resnet.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model_resnet.summary()\n",
    "\n",
    "train_datagen_resnet = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=resnet50_preprocess\n",
    ")\n",
    "val_test_datagen_resnet = ImageDataGenerator(\n",
    "    preprocessing_function=resnet50_preprocess\n",
    ")\n",
    "\n",
    "train_generator_resnet = train_datagen_resnet.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator_resnet = val_test_datagen_resnet.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_generator_resnet = val_test_datagen_resnet.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "history_resnet = model_resnet.fit(\n",
    "    train_generator_resnet,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS_TRANSFER,\n",
    "    validation_data=val_generator_resnet,\n",
    "    validation_steps=val_steps\n",
    ")\n",
    "\n",
    "plot_training_curves(history_resnet, title_prefix=\"[7] ResNet50 Frozen Conv Base\")\n",
    "\n",
    "test_loss_resnet, test_acc_resnet = model_resnet.evaluate(\n",
    "    test_generator_resnet,\n",
    "    steps=test_steps\n",
    ")\n",
    "print(\"ResNet50 Frozen Conv Base - 测试集准确率: {:.4f}\".format(test_acc_resnet))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 八、结果汇总与性能分析（作业要求）\n",
    "\n",
    "作业要求对 (2)~(7) 每一种方法进行**性能分析**，你可以：\n",
    "\n",
    "1. 将所有模型在测试集上的准确率汇总成一张表；  \n",
    "2. 简要讨论不同方法的优缺点，例如过拟合、训练速度、迁移学习提升幅度等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 11. 将各方法的测试集准确率整理成字典 / 表格\n",
    "# ======================\n",
    "\n",
    "results = {\n",
    "    \"baseline_cnn\": float(test_acc_baseline) if \"test_acc_baseline\" in globals() else None,\n",
    "    \"aug_cnn\": float(test_acc_aug) if \"test_acc_aug\" in globals() else None,\n",
    "    \"vgg16_frozen\": float(test_acc_vgg_frozen) if \"test_acc_vgg_frozen\" in globals() else None,\n",
    "    \"vgg16_feature_extract\": float(test_acc_fe) if \"test_acc_fe\" in globals() else None,\n",
    "    \"vgg16_finetune\": float(test_acc_vgg_finetune) if \"test_acc_vgg_finetune\" in globals() else None,\n",
    "    \"resnet50_frozen\": float(test_acc_resnet) if \"test_acc_resnet\" in globals() else None,\n",
    "}\n",
    "\n",
    "print(json.dumps(results, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 你的实验结论（请自行补充）\n",
    "\n",
    "> 下面是一个示例，请根据你实际跑出来的结果修改文字。\n",
    "\n",
    "- 基准 CNN 在测试集上的准确率约为 XX%，存在明显过拟合现象（训练准确率远高于验证准确率）。  \n",
    "- 引入数据增强后，验证准确率提升到 XX%，过拟合有所缓解。  \n",
    "- 直接使用预训练 VGG16（冻结卷积基）后，测试准确率达到 XX%，相比从头训练的 CNN 有明显提升。  \n",
    "- 使用 “先特征提取再训练 Dense 分类器” 的方式，性能为 XX%，但训练速度更快。  \n",
    "- 微调 VGG16 顶部卷积层后，测试准确率进一步提升 / 下降到 XX%，分析可能的原因（例如学习率、数据量）。  \n",
    "- 更换为 ResNet50 后，测试准确率为 XX%，与 VGG16 相比，表现略优 / 略差 / 相近，并给出自己的理解。  \n",
    "\n",
    "最后总结：在小数据集场景下，**基于预训练模型的迁移学习 + 合理的数据增强 + 适度微调**，通常能显著优于从头训练的 CNN。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
