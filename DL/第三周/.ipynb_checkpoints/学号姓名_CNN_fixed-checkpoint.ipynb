{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6292af14",
   "metadata": {},
   "source": [
    "# 计算机视觉基础 · 实验作业（CNN，修正版）\n",
    "**提交文件名：** 建议重命名为 `学号姓名_CNN.ipynb`  \n",
    "**创建时间：** 2025-11-11 16:17:39\n",
    "\n",
    "> 修复：B3/B4 自带兜底，避免因运行顺序导致的 `NameError`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00768935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境与版本（可选）\n",
    "import sys, numpy, sklearn, tensorflow as tf\n",
    "print(\"Python  :\", sys.version.split()[0])\n",
    "import numpy as np\n",
    "print(\"NumPy   :\", np.__version__)\n",
    "print(\"sklearn :\", sklearn.__version__)\n",
    "print(\"TF      :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通用：随机种子 + 绘图工具 + plot_history\n",
    "import os, random, numpy as np, matplotlib.pyplot as plt\n",
    "random.seed(42); np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def plot_history(hist, title_prefix=\"\"):\n",
    "    h = hist.history if hasattr(hist, 'history') else hist\n",
    "    loss = h.get('loss', h.get('train_loss', None))\n",
    "    val_loss = h.get('val_loss', None)\n",
    "    acc = h.get('accuracy', h.get('categorical_accuracy', None))\n",
    "    val_acc = h.get('val_accuracy', None)\n",
    "    if loss is not None:\n",
    "        plt.figure(); plt.plot(loss, label='train_loss')\n",
    "        if val_loss is not None: plt.plot(val_loss, label='val_loss')\n",
    "        plt.title(title_prefix + \"Loss\"); plt.legend(); plt.show()\n",
    "    if acc is not None:\n",
    "        plt.figure(); plt.plot(acc, label='train_acc')\n",
    "        if val_acc is not None: plt.plot(val_acc, label='val_acc')\n",
    "        plt.title(title_prefix + \"Accuracy\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7903e03",
   "metadata": {},
   "source": [
    "---\n",
    "# Part A —— MNIST（CNN vs 全连接）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a340a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1) 数据加载与预处理\n",
    "from tensorflow.keras import datasets\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test  = x_test.astype(\"float32\")/255.0\n",
    "x_train_cnn = np.expand_dims(x_train, -1)\n",
    "x_test_cnn  = np.expand_dims(x_test, -1)\n",
    "print(\"Train/Test:\", x_train_cnn.shape, x_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2) 全连接（MLP）基线\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "def build_mlp():\n",
    "    m = keras.Sequential([\n",
    "        layers.Input(shape=(28,28)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m\n",
    "mlp = build_mlp()\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3) 训练 MLP\n",
    "cb = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "hist_mlp = mlp.fit(x_train, y_train, validation_split=0.1, epochs=20, batch_size=128, callbacks=cb, verbose=2)\n",
    "plot_history(hist_mlp, \"[MLP] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae2e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4) CNN 模型\n",
    "def build_cnn():\n",
    "    m = keras.Sequential([\n",
    "        layers.Input(shape=(28,28,1)),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m\n",
    "cnn = build_cnn()\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c737e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5) 训练 CNN\n",
    "cb = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "hist_cnn = cnn.fit(x_train_cnn, y_train, validation_split=0.1, epochs=20, batch_size=128, callbacks=cb, verbose=2)\n",
    "plot_history(hist_cnn, \"[CNN] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e79d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A6) 测试评估 + 混淆矩阵与报告\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "mlp_pred = mlp.predict(x_test, verbose=0).argmax(axis=1)\n",
    "mlp_acc  = accuracy_score(y_test, mlp_pred)\n",
    "print(f\"[MLP] Test Acc = {mlp_acc:.4f}\")\n",
    "print(classification_report(y_test, mlp_pred, digits=3, zero_division=0))\n",
    "cm_mlp = confusion_matrix(y_test, mlp_pred)\n",
    "plt.figure(figsize=(5,5)); plt.imshow(cm_mlp, aspect='auto'); plt.title(\"Confusion Matrix - MLP\"); plt.colorbar(); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()\n",
    "\n",
    "cnn_pred = cnn.predict(x_test_cnn, verbose=0).argmax(axis=1)\n",
    "cnn_acc  = accuracy_score(y_test, cnn_pred)\n",
    "print(f\"[CNN] Test Acc = {cnn_acc:.4f}\")\n",
    "print(classification_report(y_test, cnn_pred, digits=3, zero_division=0))\n",
    "cm_cnn = confusion_matrix(y_test, cnn_pred)\n",
    "plt.figure(figsize=(5,5)); plt.imshow(cm_cnn, aspect='auto'); plt.title(\"Confusion Matrix - CNN\"); plt.colorbar(); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()\n",
    "\n",
    "res_mnist = pd.DataFrame({\"Model\":[\"MLP\",\"CNN\"], \"Test_Accuracy\":[mlp_acc, cnn_acc]})\n",
    "print(\"\\nMNIST 对比：\\n\", res_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef741b",
   "metadata": {},
   "source": [
    "---\n",
    "# Part B —— CIFAR-10（多模型对比，带兜底）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1) 数据加载与预处理\n",
    "from tensorflow.keras import datasets\n",
    "try:\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "except Exception as e:\n",
    "    print(\"CIFAR-10 加载失败：\", e)\n",
    "    print(\"解决：下载 'cifar-10-python.tar.gz' 放到 '~/.keras/datasets/' 并重命名为 'cifar-10-batches-py.tar.gz'。\")\n",
    "    raise\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test  = y_test.reshape(-1)\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test  = x_test.astype(\"float32\")/255.0\n",
    "input_shape = x_train.shape[1:]\n",
    "num_classes = 10\n",
    "print(\"Train/Test:\", x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2) 三个 CNN 结构\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def make_cnn_v1():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    m = keras.Model(inputs, outputs)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "def make_cnn_v2():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    m = keras.Model(inputs, outputs)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "def make_cnn_v3():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    aug = keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.05),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ])\n",
    "    x = aug(inputs)\n",
    "    x = layers.Conv2D(32, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D()(x); x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D()(x); x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    m = keras.Model(inputs, outputs)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc03210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3) 训练与对比（含 plot_history 兜底）\n",
    "try:\n",
    "    plot_history\n",
    "except NameError:\n",
    "    def plot_history(hist, title_prefix=\"\"):\n",
    "        import matplotlib.pyplot as plt\n",
    "        h = hist.history if hasattr(hist, 'history') else hist\n",
    "        if 'loss' in h:\n",
    "            plt.figure(); plt.plot(h['loss'], label='train_loss')\n",
    "            if 'val_loss' in h: plt.plot(h['val_loss'], label='val_loss')\n",
    "            plt.title(title_prefix + \"Loss\"); plt.legend(); plt.show()\n",
    "        if 'accuracy' in h:\n",
    "            plt.figure(); plt.plot(h['accuracy'], label='train_acc')\n",
    "            if 'val_accuracy' in h: plt.plot(h['val_accuracy'], label='val_acc')\n",
    "            plt.title(title_prefix + \"Accuracy\"); plt.legend(); plt.show()\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "\n",
    "def train_and_eval(build_fn, name, epochs=20, batch_size=128):\n",
    "    m = build_fn()\n",
    "    print(f\"\\n===== Training {name} =====\")\n",
    "    hist = m.fit(x_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=2)\n",
    "    plot_history(hist, f\"[{name}] \")\n",
    "    tl, ta = m.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"[{name}] Test Acc = {ta:.4f}\")\n",
    "    return m, ta\n",
    "\n",
    "models, scores = {}, {}\n",
    "for name, fn in [(\"CNN_v1_base\", make_cnn_v1), (\"CNN_v2_moreconv\", make_cnn_v2), (\"CNN_v3_aug_bn\", make_cnn_v3)]:\n",
    "    m, acc = train_and_eval(fn, name, epochs=20, batch_size=128)\n",
    "    models[name] = m; scores[name] = acc\n",
    "\n",
    "import pandas as pd\n",
    "res_df = pd.DataFrame({\"Model\": list(scores.keys()), \"Test_Accuracy\": [scores[k] for k in scores]}).sort_values(\"Test_Accuracy\", ascending=False)\n",
    "print(\"\\nCIFAR-10 对比：\\n\", res_df)\n",
    "res_df.to_csv(\"CIFAR10_model_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4) 最佳模型报告 + 混淆矩阵（检测 res_df 是否存在）\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "if 'res_df' not in globals() or 'models' not in globals():\n",
    "    raise RuntimeError(\"未检测到 B3 结果。请先运行 B3（训练与对比）再执行本单元。\")\n",
    "\n",
    "best_name = res_df.iloc[0][\"Model\"]\n",
    "best_model = models[best_name]\n",
    "print(\"最佳模型：\", best_name)\n",
    "y_pred = best_model.predict(x_test, verbose=0).argmax(axis=1)\n",
    "print(classification_report(y_test, y_pred, digits=3, zero_division=0))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,6)); plt.imshow(cm, aspect='auto'); plt.title(f\"Confusion Matrix - {best_name}\"); plt.colorbar(); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b88d306",
   "metadata": {},
   "source": [
    "---\n",
    "## 数据放置说明（离线时）\n",
    "- **MNIST**：`~/.keras/datasets/mnist.npz`（联网时自动下载并缓存）。  \n",
    "- **CIFAR-10**：下载 `cifar-10-python.tar.gz` → 放 `~/.keras/datasets/` → 改名为 `cifar-10-batches-py.tar.gz`。\n",
    "Windows 路径通常：`C:\\Users\\<你的用户名>\\.keras\\datasets\\`。"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
