{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通用：随机种子 + 绘图工具（matplotlib）\n",
    "import os, random, numpy as np, matplotlib.pyplot as plt\n",
    "random.seed(42); np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def plot_history(hist, title_prefix=\"\"):\n",
    "    h = hist.history if hasattr(hist, 'history') else hist\n",
    "    loss = h.get('loss', h.get('train_loss', None))\n",
    "    val_loss = h.get('val_loss', None)\n",
    "    acc = h.get('accuracy', h.get('categorical_accuracy', None))\n",
    "    val_acc = h.get('val_accuracy', None)\n",
    "    if loss is not None:\n",
    "        plt.figure(); plt.plot(loss, label='train_loss')\n",
    "        if val_loss is not None: plt.plot(val_loss, label='val_loss')\n",
    "        plt.title(title_prefix + \"Loss\"); plt.legend(); plt.show()\n",
    "    if acc is not None:\n",
    "        plt.figure(); plt.plot(acc, label='train_acc')\n",
    "        if val_acc is not None: plt.plot(val_acc, label='val_acc')\n",
    "        plt.title(title_prefix + \"Accuracy\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5cce2e",
   "metadata": {},
   "source": [
    "\n",
    "MNIST（CNN vs 全连接）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1) 数据加载与预处理\n",
    "from tensorflow.keras import datasets\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test  = x_test.astype(\"float32\")/255.0\n",
    "x_train_cnn = np.expand_dims(x_train, -1)\n",
    "x_test_cnn  = np.expand_dims(x_test, -1)\n",
    "print(\"Train/Test:\", x_train_cnn.shape, x_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2) 全连接（MLP）基线\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "def build_mlp():\n",
    "    m = keras.Sequential([\n",
    "        layers.Input(shape=(28,28)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m\n",
    "mlp = build_mlp()\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3) 训练 MLP\n",
    "cb = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "hist_mlp = mlp.fit(x_train, y_train, validation_split=0.1, epochs=20, batch_size=128, callbacks=cb, verbose=2)\n",
    "plot_history(hist_mlp, \"[MLP] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4) CNN 模型\n",
    "def build_cnn():\n",
    "    m = keras.Sequential([\n",
    "        layers.Input(shape=(28,28,1)),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m\n",
    "cnn = build_cnn()\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46653c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5) 训练 CNN\n",
    "cb = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "hist_cnn = cnn.fit(x_train_cnn, y_train, validation_split=0.1, epochs=20, batch_size=128, callbacks=cb, verbose=2)\n",
    "plot_history(hist_cnn, \"[CNN] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19309f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A6) 测试评估 + 混淆矩阵与报告\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "mlp_pred = mlp.predict(x_test, verbose=0).argmax(axis=1)\n",
    "mlp_acc  = accuracy_score(y_test, mlp_pred)\n",
    "print(f\"[MLP] Test Acc = {mlp_acc:.4f}\")\n",
    "print(classification_report(y_test, mlp_pred, digits=3, zero_division=0))\n",
    "cm_mlp = confusion_matrix(y_test, mlp_pred)\n",
    "plt.figure(figsize=(5,5)); plt.imshow(cm_mlp, aspect='auto'); plt.title(\"Confusion Matrix - MLP\"); plt.colorbar(); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()\n",
    "\n",
    "cnn_pred = cnn.predict(x_test_cnn, verbose=0).argmax(axis=1)\n",
    "cnn_acc  = accuracy_score(y_test, cnn_pred)\n",
    "print(f\"[CNN] Test Acc = {cnn_acc:.4f}\")\n",
    "print(classification_report(y_test, cnn_pred, digits=3, zero_division=0))\n",
    "cm_cnn = confusion_matrix(y_test, cnn_pred)\n",
    "plt.figure(figsize=(5,5)); plt.imshow(cm_cnn, aspect='auto'); plt.title(\"Confusion Matrix - CNN\"); plt.colorbar(); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()\n",
    "\n",
    "res_mnist = pd.DataFrame({\"Model\":[\"MLP\",\"CNN\"], \"Test_Accuracy\":[mlp_acc, cnn_acc]})\n",
    "print(\"\\nMNIST 对比：\\n\", res_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f0fb4",
   "metadata": {},
   "source": [
    "\n",
    "多模型对比\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1) 数据加载与预处理\n",
    "from tensorflow.keras import datasets\n",
    "try:\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "except Exception as e:\n",
    "    print(\"CIFAR-10 加载失败：\", e)\n",
    "    print(\"解决：下载 'cifar-10-python.tar.gz' 放到 '~/.keras/datasets/' 并重命名为 'cifar-10-batches-py.tar.gz'。\")\n",
    "    raise\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test  = y_test.reshape(-1)\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test  = x_test.astype(\"float32\")/255.0\n",
    "input_shape = x_train.shape[1:]\n",
    "num_classes = 10\n",
    "print(\"Train/Test:\", x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2) 定义三个 CNN 结构\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def make_cnn_v1():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    m = keras.Model(inputs, outputs)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "def make_cnn_v2():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    m = keras.Model(inputs, outputs)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "def make_cnn_v3():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    aug = keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.05),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ])\n",
    "    x = aug(inputs)\n",
    "    x = layers.Conv2D(32, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D()(x); x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D()(x); x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    m = keras.Model(inputs, outputs)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3) 训练与对比\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "\n",
    "def train_and_eval(build_fn, name, epochs=20, batch_size=128):\n",
    "    m = build_fn()\n",
    "    print(f\"\\n===== Training {name} =====\")\n",
    "    hist = m.fit(x_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=2)\n",
    "    plot_history(hist, f\"[{name}] \")\n",
    "    tl, ta = m.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"[{name}] Test Acc = {ta:.4f}\")\n",
    "    return m, ta\n",
    "\n",
    "models, scores = {}, {}\n",
    "for name, fn in [(\"CNN_v1_base\", make_cnn_v1), (\"CNN_v2_moreconv\", make_cnn_v2), (\"CNN_v3_aug_bn\", make_cnn_v3)]:\n",
    "    m, acc = train_and_eval(fn, name, epochs=20, batch_size=128)\n",
    "    models[name] = m; scores[name] = acc\n",
    "\n",
    "import pandas as pd\n",
    "res_df = pd.DataFrame({\"Model\": list(scores.keys()), \"Test_Accuracy\": [scores[k] for k in scores]}).sort_values(\"Test_Accuracy\", ascending=False)\n",
    "print(\"\\nCIFAR-10 对比：\\n\", res_df)\n",
    "res_df.to_csv(\"CIFAR10_model_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4) 最佳模型报告 + 混淆矩阵\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "best_name = res_df.iloc[0][\"Model\"]\n",
    "best_model = models[best_name]\n",
    "print(\"最佳模型：\", best_name)\n",
    "y_pred = best_model.predict(x_test, verbose=0).argmax(axis=1)\n",
    "print(classification_report(y_test, y_pred, digits=3, zero_division=0))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,6)); plt.imshow(cm, aspect='auto'); plt.title(f\"Confusion Matrix - {best_name}\"); plt.colorbar(); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6721f1",
   "metadata": {},
   "source": [
    "\n",
    "## 实验过程与模型意义\n",
    "- **MNIST：** CNN 利用空间局部性与权重共享，较 MLP 更适合图像；早停/降学习率帮助稳定训练并抑制过拟合。  \n",
    "- **CIFAR-10：** 增加卷积层（v2）与使用数据增强 + BN + Dropout（v3）提升泛化；代价是训练时间更长。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
